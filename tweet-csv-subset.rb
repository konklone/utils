#!/usr/bin/env ruby

##
# Given a tweets.json from a Twitter export (which is tweets.js
# after having the piece of non-JSON text at the top removed),
# this will run through it given various conditions and create
# a slimmer subset of that CSV designed for human review,
# before potentially feeding to something like TwitterDelete or
# some other script that processes them in bulk.

require 'csv'
require 'oj'


## Very specific to my own work.
FLAG_TEXT = [
  "konklone.com",
  "isitchristmas.com",
  "shaaaaaaaaaaaaa.com",
  "https.cio.gov",
  "pulse.cio.gov",
  "github.com/konklone",
  "github.com/unitedstates",
  "analytics.usa.gov",
  "theunitedstates.io",
  "konklone.io",
  "sunlightfoundation.com",
]

# Condition on which a tweet will get included in the output CSV.
#
# Hand-comment and -uncomment these for whatever conditions you want.
def condition?(tweet, preserve_these, still_alive)
  (
    # Contains flagged text.
    # contains_text_from(tweet["full_text"], FLAG_TEXT) and

    # Always ignore those in preserve-these.csv.
    (not preserve_these.include?(tweet["id"])) and

    # Look in a export of known-still-alive tweets.
    (still_alive.include?(tweet["id"])) and

    # Filter on like and RT count.
    # (
    #   (
    #     (tweet["favorite_count"].to_i > 5) and
    #     (tweet["favorite_count"].to_i <= 50)
    #   ) or
    #   (
    #     (tweet["retweet_count"].to_i > 5) and
    #     (tweet["retweet_count"].to_i <= 50)
    #   )
    # ) and

    # Ignore replies.
    (!tweet["full_text"].start_with?("@")) # and

    # Only replies.
    # (tweet["full_text"].start_with?("@")) # and

    # Limit to those with no activity.
    # (tweet["retweet_count"].to_i == 0) and
    # (tweet["favorite_count"].to_i == 0) and

    # Time bound.
    # (Time.parse(tweet["created_at"]).year >= 2013) # and

    # Ignore RTs.
    # (not is_retweet?(tweet))

    # Only RTs.
    # is_retweet?(tweet)

  )
end

# ETL
def main
  tweets = Oj.strict_load(File.read("tweets.json"))

  # Preserve any tweet IDs in this file. Expects a header row.
  # It's expected you'll paste/append IDs by hand into this file
  # as you review the tweets generated by runs of this script.
  preserve_these = CSV.read("preserve-these.csv").flatten[1..-1]

  # Grab a CSV of known-still-alive tweet IDs.
  # It's expected this will be generated by a separate script that
  # looks over which tweets are still alive in an account.
  still_alive = CSV.read("still-alive.csv").flatten[1..-1]

  # Always outputs to tweets-slim.csv.
  csv = CSV.open("tweets-slim.csv", "w")
  csv << HEADERS

  met = []
  skipped = []

  tweets.each do |tweet|
    expand_links! tweet

    if condition?(tweet, preserve_these, still_alive)
      met << tweet

      puts "[%s] Including tweet..." % tweet["id"]
      csv << tweet_to_row(tweet)
    else
      skipped << tweet
    end
  end

  puts "Condition met: %i" % met.size
  puts "Skipped: %i" % skipped.size

  csv.close
end

HEADERS = [
  "tweet_id", # matches TweetDelete expectation
  "year",
  "full_text",
  "created_at",
  "retweet_count",
  "favorite_count",
  "in_reply_to_screen_name",
  "is_retweet",
]

def tweet_to_row(tweet)
  created_at = Time.parse(tweet["created_at"])
  [
    tweet["id"],
    created_at.year,
    tweet["full_text"],
    created_at.to_s,
    tweet["retweet_count"],
    tweet["favorite_count"],
    tweet["in_reply_to_screen_name"],
    is_retweet?(tweet)
  ]
end

def is_retweet?(tweet)
  tweet["full_text"].start_with?("RT @")
end

# Return a tweet body with links expanded.
def expand_links!(tweet)
  full_text = tweet["full_text"]
  entities = tweet["entities"]
  extended_entities = tweet["extended_entities"]

  entities["urls"].each do |url|
    full_text[url["url"]] = url["expanded_url"]
  end

  if extended_entities
    # One t.co URL can map to multiple media entities
    already_matched = []
    extended_entities["media"].each do |media|
      unless already_matched.include?(media["url"])
        full_text[media["url"]] = media["media_url_https"]
      end
      already_matched << media["url"]
    end
  end
end

def contains_text_from(full_text, strings)
  strings.each do |string|
    return true if full_text.include?(string)
  end
  false
end

main
